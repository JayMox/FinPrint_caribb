---
title: "Wrgl_FishCounts_raw"
author: "Jerry Moxley"
date: "2/15/2022"
output: html_document
---
Aim: document database assembly of Caribb reef survey data, primarily raw survey counts of reef fish.  

Database is survey count of species BY country/survey loc/BRUV surveyID.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(here)
source(here('r', 'fxn_library.R'))
```

##effort DB Initialize
Initalize an database for tracking survey effort across methods
```{r}
#initalize lkup_surveyeffort from BRUV data
  #initalize lkup_surveyeffort from BRUV data
srvy <- read_csv(here('data', 'summStats_tbl_4.csv')) %>% 
    janitor::clean_names() %>%
    select(reef_id, trip_year, location_name, site_name, reef_name) %>% 
    mutate(
           ##sampling site meta data
           country = location_name,
           site.zone = site_name, 
           site.reef = paste(site_name, reef_name, trip_year, sep = "_"),
           site.reefcode = reef_id, 
           lat = NA, lon = NA, year = trip_year,
           
           ##srvy Params
           srvy.type = "bruv", #OR uvc.f[ish] uvc.b[enthic]
           srvy.method = "cam", #OR radial[uvc], belt[uvc], quad[rat]
           srvy.taxa = "elasmo", #elasmo, fish, benthos
           d2bruv = NA, #dist to bruv [unit]
           fpid = NA, #assigned bruv id based on proximity
           n.obs = NA, #n of samples in src data
           
           ##effort params
           eff.nsamples = NA, #number of transect samples
           eff.nsrvyed = NA, #number of srveyed 
           eff.pue = NA, #number for PUE standardization
           eff.unit = NA, #m2 or perMin(??)
           
           ##file tracking mgmt
           #is it stitched in[t/f], raw src [file], raw out [file]
           stitch.ed = NA,
           stitch.in =  "BRUVmaxn_elasmobranch_observations_all.csv", 
           stitch.out = "src_BRUV_westernAtl.csv",
           dat.partner = "finprint"
           
           ) %>% 
    select(-location_name, -site_name, -reef_id, -trip_year, -reef_name)

###BRUV sweep
bruv <- read_csv(here('data/stitch', 'src_BRUV_westernAtl.csv'))
  # merge(
  #   #merge bruv data here
  #   #or do in separate wrgnl process.. <<<- probs this!
  # )
  #   write_csv(here('data', 'lkup_surveyeffort.csv')
  # )
```
Follow up
wrangle bruv effort into lkup table
change eff.nsites to eff.nsamples or eff.ntransects

## Belize

Data cleaning is done for Glovers Reef and SWCMR. 
Needs file wrangling into overall pipeline. 
lkup_Blz_areaStandardization_Jan22 is db structure src.  

RAW DATA has size classes, if size mediated bc impt.
SRC DATA is from initial dens ests; hand copies of sheets in wintr 22.


EFFORT
lkup_belize_areaStandardization.csv shows sites where data was only inputted for fewer than total of that's reef's yrly 8 transects.  

Default effort is 8 transects/site w/ 60m tubes.. coded by max(transect) for a site/year pair.     

No lat/lons currently.

site.zone defined as Glovers/GRMR or SWCMR.  Site.reef and Site.reef code are the same, but maybe should use designations baked into site code.  

```{r cars}
#wrangle
source(here('r', 'wrngl_uvc_belize.R'))

#LOTTA LOTTA FOLLOW UPS HERE.  
```
follow up.. 
- lil confusd on assignment of site reef & site reef code.  I believe src$site is for an individual reef.  Not sure how to assign zone.  On 2/17, site and site.reef & site.reef.code are assigned the same id src>site.  Eval if should be the locale baked into the reef cof
- consider pre summary of belize data (??)
- needs spp codes incorporated
- for loop needs water tightening 
- no lat/lons
- Should the agg over size classes be done prior to stitch/src data?  
- do you want remaining fields from lkup_samplingSites
- DOUBLE CHECK MERGE ON SITES & RESERVES.. THERE ARE MIRRORING SITE CODES BW RESERVE ZONES.  I **THINK** they are in opposing odd/even years tho.  - dupes in the effort database??
- get spp.ncodr working
- DOUBLE DOUBLE CHECK ASSINGMNET OF MERGERS wrt to year/site/zone pairs
- I thnk technically I should move the new field definition out of the for loop into the df call.. double chk
-DUPES IN THE DF.. def a problem with reserve assignment.  Re-eval!!

## Colombia
30x2m Tubes (in simac metodos.pdf)
Somera and Media depths (ignoring this distinction rn)
Only a subset of families monitored (see screenshot)

Islas Rosario 
FP 478_2016 at Isla Grande (10.1784107	-75.75384933)
FP 479_2016 at Isla Tesoro (10.23514	-75.74047)
6 other "b" sites surveyed in Rosario archipel

Islas Bernardo
FP480_2016 at Tintipan (2 uvc depths avail).. (9.7858667	-75.7885083)
FP481_2016 at Mangle (2 uvc locs avail)..     (9.75363335	-75.796425)
6 other "b" sites surveyed in Bernardo archipel

code for avg locs
bruv %>% filter(location_name == "Colombia") %>% filter(reef_id == "481") %>% summarize(lat = mean(set_lat), lon = mean(set_long)) %>% unlist()
```{r pressure, echo=FALSE}
source(here('r', 'wrngl_uvc_colombia.R'))
#calc density at basal level

#arrange effort according to srvy fields
#effort %>% select(colnames(srvy)) %>% colnames

##bind dat w/ relevant master df's
```

Follow ups:
-Numbers in ptnr-provided "Transectos por estaciones de monitoreo" do not match data src. 
-still need to bind outputs into the master df
- get spp encoder going into 'spp' field

Wrangle debrief: 
Straight-forwarded, raw provided in spp counts X transect/site/region.  One encoding error with a spp.  60m2 belt transects  only recorded subset of "selected spp" (may be quasi-citSci data).  Can be sampled at a per-transect basis, as is.  

##  Cuba
Values provided are densities, back-calculated to counts via effort info seen below (and in .xlsx of raw data).
Biomass data also available, ignored for now. 

From raw data
16 sites on reef slope 15-20 m deep in 2018.
10 belt transcts 50 m x 4 m per site.
Species list includes large fishes (target by fisheries), herbivorous and medium size fishes, mainly urchin predators.
Data are density per site on individuals/100 m2

```{r}
source(here('r', 'wrngl_uvc_cuba.R'))

#wrangle effort into srvy table
```
Follow up:
- need to develop wrangling of the effort for lkup table.  
- make site ref codes
- could build easy sampler for bootstrapping transects

##Caicos
- reported in density data, back calc' to spp count. 
- uvc tube is 2x100 acc to Ruth's methods (actually seems tube dims are reported alongside the data).. (ACCORDING TO EMAIL, IT'S A 4X2X100M TUBE)
- has designated student VS staff-conducted surveys, structured seasonally/yrly

-only input surveys w/ counts reported (i.e., filter out sampling like (single, few, many, abundant)
-has trophic assignment based on chaplin paper, may be worthwhile comparison w/ paddack assignments
- does have size data
- don't know what the time field is about
- has depth data
- effort sites are based on site name & season (date surveyed is unique to season, acc. to this code: dat %>% group_by(year, season, site) %>% distinct(date)
- vast majority of 2016 surveys are student-leds


```{r}
#source script here
source(here('r', 'wrngl_uvc_caicos.R'))
```

- needs follow up on site assignment & which sites are valuable samplers for South Caicos reserve
- site.zone is hard-coded as "South Caicos"
- has some rando site names (apply to surveys in 2014-2015)
- might require someway to reconcile date of survey & a transect index.. impacts how nsites & nsrveys is calc'ed (which is hella important)
- i don't understand "transect" as a field

-FAIRLY GOOD EMAIL CORRESPONDENCE THAT SHOULD BE MINED AND ALIGNED
-maybe quick analysis comapring student- v staff-led?
- decision necessary about # of years to include, w/ finprint data
- decision about how to handle season data? (as Feb 22, site.reefcode has season baked into it)
-transect is set as date, could be indexed

-EFFORT df needs big attn!! (both in the summarization, and in the merger w/ df)
- Evaluate the duplicates in the spp data

##FLORIDA
radial transects.. lots of zeros, extensive spp list. 
src field desc: https://grunt.sefsc.noaa.gov/rvc_analysis20/samples/index

src data is entirely 2016, but applies to BRUVS sampling in 2016 (4 surveys) and 2017 (n = 2 srvys) BRUV sr

could pull 2017 data via curl script (in data/raw)?

potential for taxa list as a lkup tbl?

src data has length & num fields.. but num are doubles, look kinda like densities (some massive numbers too??)
acc to data diction:
LEN: The length, in cm, of a sample.
NUM: The number of individuals of a given species and length observed in a secondary sampling unit.

effort structure
ctry - 'florida'
zone - subregion_nr [8:12] (applies to uppper/lower keys?)
reef - primary sampling unit
transect - (secondary) station number (ie. 2 radial transects per sample)


```{r}
#source script here

```
methods details for data collection: https://nsuworks.nova.edu/cgi/viewcontent.cgi?article=1093&context=occ_facreports/

-what to do w/ habitat codes, maritime zone (inshore, offshore, midchannel, forereef)
-eff. values essentially NA
- using NOAA provided species code
- evaluate lkup tbl for spp data, using noaa list as src.
- evlauate data pull on 2017 data
- NEEDS HELLA ATTN  to assingmnet of site zone, reef, & transect numbers
- NOT SURE IF needs group_by statements for comparable numbers
-whats up w/ counts being decimals (i think this is the avg bw transect 1 and 2 at a site, see density methods in this paper: https://nsuworks.nova.edu/cgi/viewcontent.cgi?article=1093&context=occ_facreports/)

##FULL FOLLOW UP
 - determine what to do with the integration fields
 - get field names straight bw . & _.. particularly if janitor::clean_names((0)) is gettitng called. 
 - is n.obs a useful metric at all? probably worthwhile compiling this at the end when data is agg'ed
 - wont data df's need a zone col?
 - get spp.ncodr working.
